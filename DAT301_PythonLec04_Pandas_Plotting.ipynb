{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26a7d9ce",
   "metadata": {},
   "source": [
    "\n",
    "### Review of Pandas, Basic Data Loading, and Pandas Plotting\n",
    "\n",
    "#### Quick Review:\n",
    "\n",
    "- Recall our fundamental objects: Series and DataFrames\n",
    "- `apply` and element-wise operations\n",
    "- Summarizing and computing descriptive statistics\n",
    "- Python variable name binding\n",
    "\n",
    "#### The Main Stuff:\n",
    "\n",
    "- Loading data\n",
    "- grouping\n",
    "- plotting, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c4aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import our basic libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d97a0c",
   "metadata": {},
   "source": [
    "#### Series\n",
    "\n",
    "The two fundamental data structures in pandas are the *Series* and *DataFrame*\n",
    "\n",
    "**Series** is a 1-D array-like object with sequence of values (types similar to NumPy types) + array of data labels called its *index*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56091a5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Make simple series and give the index some labels\n",
    "obj = pd.Series([1, 3, 5, 7], index = ['a', 'b', 'c', 'd'])\n",
    "\n",
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e311739",
   "metadata": {},
   "source": [
    "Can use either numeric index or labels in index to select values:\n",
    "\n",
    "(Note possible ambiguity when labels are numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc3b0a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obj[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97da9bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note the right index is included with this format!\n",
    "obj['a':'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5236acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note must use a list if getting multiple specific indices\n",
    "obj[['a', 'b', 'd']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d845ca4",
   "metadata": {},
   "source": [
    "#### Selection with loc and iloc\n",
    "\n",
    "Select subsets of rows and columns using either axis labels (loc) or integer index (iloc)\n",
    "\n",
    "- `loc`: Strictly label-based access\n",
    "- `iloc`: Strictly integer-based access\n",
    "\n",
    "Especially important when you have integer-valued labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8f52de",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.iloc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617c0455",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.loc['a':'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.loc[['a', 'c', 'd']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0034fd87",
   "metadata": {},
   "source": [
    "#### Boolean Masking\n",
    "\n",
    "Similar to NumPy, R, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dad6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_obj = obj > 3\n",
    "type(bool_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.loc[bool_obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6106a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note boolean masking by a list of values:\n",
    "obj.isin([5,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d306a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And:\n",
    "obj.loc[obj.isin([5,7])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dee99a",
   "metadata": {},
   "source": [
    "Can directly create a Series from data stored in a dictionary object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf38f3aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Area harvested for grain in 2020 in 1,000 acres, selected states; USDA Acreage Report\n",
    "#https://usda.library.cornell.edu/concern/publications/j098zb09z?locale=en\n",
    "####\n",
    "sdata = {'Arizona': 29, 'Ohio': 3300, 'Texas': 1810, 'Oregon': 65, 'Iowa': 12900}\n",
    "\n",
    "#Also set order, get NaNs if ask for anything not in the dictionary\n",
    "states = ['Iowa', 'Arizona', 'Texas', 'Ohio', 'California']\n",
    "\n",
    "obj = pd.Series(sdata, index = states)\n",
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c039272",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "\n",
    "Similar to R, rectangular table of data, where each column can be a different data type.\n",
    "\n",
    "- Both row and column index\n",
    "\n",
    "- Can also think of as a dict of Series all sharing same index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55feb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's make a DataFrame from a dict of equal-length lists:\n",
    "#Index is assigned automatically\n",
    "\n",
    "#Principal Crops Area Planted\n",
    "#USDA Acreage Report\n",
    "#https://usda.library.cornell.edu/concern/publications/j098zb09z?locale=en\n",
    "\n",
    "data = {'state': ['Arizona', 'Arizona', 'Arizona', 'California', 'California', 'California', 'Iowa', 'Iowa', 'Iowa'],\n",
    "        'year': [2019, 2020, 2021, 2019, 2020, 2021, 2019, 2020, 2021],\n",
    "        'area planted': [637, 573, 616, 2983, 2621, 2550, 23935, 24330, 24330]}\n",
    "        \n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8396eeee",
   "metadata": {},
   "source": [
    "**Recall selection with loc and iloc**\n",
    "\n",
    "Select subsets of rows and columns using either axis labels (`loc`) or integer index (`iloc`)\n",
    "- `loc`: Strictly label-based access\n",
    "- `iloc`: Strictly integer-based access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb0e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For example:\n",
    "df = pd.DataFrame(np.arange(16).reshape(4, 4),\n",
    "                  index = ['one', 'two', 'three', 'four'],\n",
    "                  columns = ['C1', 'C2', 'C3', 'C4'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e1218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic loc:\n",
    "\n",
    "#Note this:\n",
    "df.loc['one']\n",
    "\n",
    "#vs. this:\n",
    "df.loc['one':'one']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25463ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['one', ['C1','C2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iloc examples:\n",
    "###\n",
    "\n",
    "df.iloc[2] #Try :2, :3\n",
    "#df.iloc[2,:]\n",
    "\n",
    "#df.iloc[[0,2,3]]\n",
    "\n",
    "#df.iloc[1:3, 2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce96b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note again the asymmetry between iloc and loc for the end index:\n",
    "###\n",
    "\n",
    "df.loc['one':'three', 'C2':'C4']\n",
    "\n",
    "df.iloc[1:3, 2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f783fdc",
   "metadata": {},
   "source": [
    "#### Function Application and Mapping\n",
    "\n",
    "NumPy ufuncs also work on pandas objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d5c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(4,3).round(2),\n",
    "                  columns = list('ABC'),\n",
    "                  index = list('abcd'))\n",
    "\n",
    "display(df)\n",
    "\n",
    "display(np.sqrt(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088173f6",
   "metadata": {},
   "source": [
    "`apply` method: Applies a function across columns or rows, similar to apply in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f63b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(12).reshape(4,3),\n",
    "                  columns = list('ABC'),\n",
    "                  index = list('abcd'))\n",
    "\n",
    "display(df)\n",
    "\n",
    "#By default, applies down the columns, can change axis:\n",
    "df.apply(np.sum, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6724b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can use our own functions. Recall lambda keyword:\n",
    "f = lambda x: x.max() - x.min()\n",
    "\n",
    "df.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10483a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also similar to R, can return more than a single scalar:\n",
    "#Can also return a Series with multiple values:\n",
    "f = lambda x: pd.Series([x.min(), x.max()], index=['min', 'max'])\n",
    "\n",
    "df.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: apply not usually necessary for common array statistical functions:\n",
    "######\n",
    "\n",
    "np.mean(df, axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9f53bc",
   "metadata": {},
   "source": [
    "To use an element-wise Python function with a DataFrame, use `applymap` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77c8263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts the input to a string, add 'S'\n",
    "f = lambda x: str(x) + 'S'\n",
    "\n",
    "df.applymap(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dece214f",
   "metadata": {},
   "source": [
    "#### More Sorting and Ranking\n",
    "\n",
    "We can sort by row or column index, using the `sort_index` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab858b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[4,1,2], [1,9,0], [0,5,2], [9,5,1]],\n",
    "                  columns = list('BAC'),\n",
    "                  index = list('bcad'))\n",
    "\n",
    "#df\n",
    "df.sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc06fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7333654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45091d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And again, to sort by values:\n",
    "#df.sort_values(by = ['A'])\n",
    "\n",
    "df.sort_values(by = ['A','C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc5bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can also rank items in a DataFrame\n",
    "####\n",
    "\n",
    "df.rank()\n",
    "#df.rank(method=\"first\")\n",
    "\n",
    "#df.rank(axis=\"columns\", method=\"first\")\n",
    "\n",
    "#method options: average, min, max, first, dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79265f9d",
   "metadata": {},
   "source": [
    "#### Summarizing and Computing Descriptive Statistics\n",
    "\n",
    "- pandas objects have set of common mathematical and statistical methods\n",
    "- Usualy reductions or summary statistics: yield single value for Series, Series of values from rows or columns of a DataFrame\n",
    "- Built-in handling for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7439993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple example:\n",
    "df = pd.DataFrame([[1, np.nan], [2, 3], [4, np.nan], [5,6]],\n",
    "                  index = list('abcd'),\n",
    "                  columns = ['one', 'two'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f6744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sum down the columns, ignoring NaNs:\n",
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac8e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sum across the columns, i.e. by index:\n",
    "df.sum(axis='columns') #Or axis = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e01c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can do skipna = False:\n",
    "df.sum(axis=1, skipna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131ab9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#idxmin and idxmax return index labels where min and max values attained:\n",
    "#argmin and argmax retun index locations (integers) where min and max attained\n",
    "\n",
    "#display(df.max().max())\n",
    "\n",
    "df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3292944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can do cumulative sums and products:\n",
    "df.cumsum()\n",
    "#df.cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e8e9fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#And a bunch of summary statistics:\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f88ff7",
   "metadata": {},
   "source": [
    "Methods:\n",
    "- `count`\n",
    "- `describe`\n",
    "- `min`, `max`\n",
    "- `argmin`, `argmax`\n",
    "- `idxmin`, `indxmax`\n",
    "- `quantile`\n",
    "- `sum`\n",
    "- `mean`\n",
    "- `median`\n",
    "- `mad` (mean absolute deviation from mean)\n",
    "- `prod`\n",
    "- `var`\n",
    "- `std`\n",
    "- `skew`\n",
    "- `kurt`\n",
    "- `cumsum`\n",
    "- `cummin`, `cummax`\n",
    "- `cumprod`\n",
    "- `diff` (first arithmetic difference)\n",
    "- `pct_change`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e689308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e65e0e6",
   "metadata": {},
   "source": [
    "#### Finally: Variable name binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9158930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remake our old df:\n",
    "####\n",
    "\n",
    "data = {'state': ['Arizona', 'Arizona', 'Arizona', 'California', 'California', 'California', 'Iowa', 'Iowa', 'Iowa'],\n",
    "        'year': [2019, 2020, 2021, 2019, 2020, 2021, 2019, 2020, 2021],\n",
    "        'area planted': [637, 573, 616, 2983, 2621, 2550, 23935, 24330, 24330]}\n",
    "        \n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ed90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df\n",
    "\n",
    "df2 is df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[df2['state'] == 'Arizona', 'year'] = [1,2,3]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a616a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also Note:\n",
    "#To get cells by column values:\n",
    "#display(df2.loc[(df2['state'] == 'California')])\n",
    "\n",
    "display(df2.loc[(df2['state'] == 'California') & (df2['year'] == 2019)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b95b74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or just:\n",
    "df2[(df2['state'] == 'Arizona') & (df2['year'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4780cb7f",
   "metadata": {},
   "source": [
    "### Basic Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e7e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's load some data on carbon emissions by nation\n",
    "#######\n",
    "url_name = r'https://zenodo.org/record/4281271/files/nation.1751_2017.csv?download=1'\n",
    "\n",
    "df = pd.read_csv(url_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see what we got:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8479575",
   "metadata": {},
   "source": [
    "Obviously some issues...Let's download and look at the .csv file in Excel and look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab1bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "#URL for file\n",
    "url_name = r'https://zenodo.org/record/4281271/files/nation.1751_2017.csv?download=1'\n",
    "\n",
    "#Local file name to save to\n",
    "local_file = r'Data/nation.1751_2017.csv'\n",
    "\n",
    "#Download and save\n",
    "request.urlretrieve(url_name, local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234d32cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looks like we have some front matter taking up 4 lines, so...\n",
    "#Can either use header = 4\n",
    "#OR\n",
    "#skiprows = 4\n",
    "\n",
    "#skiprows can also be a list, not just a number!\n",
    "\n",
    "#Note: MUCH faster to read the local file, vs. the url\n",
    "df = pd.read_csv(local_file, header = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a1a4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2edad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can set different columns names on reading like so:\n",
    "#######\n",
    "\n",
    "name_list = ['Nation', 'Year', 'Total', 'Solid', 'Liquid', 'Gas', 'Cement', 'Flaring', 'Per_Capita', 'Bunker']\n",
    "\n",
    "#Use header = 4, or somewhat more verbose:\n",
    "df = pd.read_csv(local_file, skiprows = 5, header = None, names = name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3539da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db82519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see what all the unique nations are:\n",
    "################\n",
    "\n",
    "display(df.Nation.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827907fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And how many are there?\n",
    "\n",
    "display(len(df.Nation.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250bbde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And let's look at the US: Note the trailing white space\n",
    "df.loc[df['Nation'] == 'UNITED STATES OF AMERICA '].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded82a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can strip the leading and trailing whitespace from our Nation names:\n",
    "#Use lstrip() and rstrip() for just leading/following:\n",
    "\n",
    "df.Nation = df.Nation.str.strip()\n",
    "\n",
    "df.loc[df['Nation'] == 'UNITED STATES OF AMERICA'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d4e8de",
   "metadata": {},
   "source": [
    "Note that it looks like we have a lot of missing data...\n",
    "And note our data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c26737f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get our data types:\n",
    "####\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d4adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a0ec27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#There are a few ways to deal with this...\n",
    "\n",
    "#First note what these values are:\n",
    "display(df.iloc[0,8])\n",
    "\n",
    "#And note that there is a space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b6507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One option is to reload:\n",
    "#####\n",
    "\n",
    "name_list = ['Nation', 'Year', 'Total', 'Solid', 'Liquid', 'Gas', 'Cement', 'Flaring', 'Per_Capita', 'Bunker']\n",
    "\n",
    "df = pd.read_csv(local_file, header = 4, names = name_list, na_values = '. ')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad2a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now our types?\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d001ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also specify types when loading:\n",
    "#Use a dictionary:\n",
    "#######\n",
    "\n",
    "df = pd.read_csv(local_file, header = 4, names = name_list, na_values = '. ',\n",
    "                 dtype = {'Total': np.float64, 'Cement': np.float64, 'Bunker': np.float64})\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506cf551",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Could also force the columns to a numeric type AFTER loading\n",
    "###\n",
    "\n",
    "df = pd.read_csv(local_file, header = 4, names = name_list)\n",
    "\n",
    "#This will fail: Can't convert a string\n",
    "df.Flaring.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07a10ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will work: Use pd.to_numeric function\n",
    "#Set errors = coerce so that if invalid parsing, give a NaN\n",
    "df.Flaring = pd.to_numeric(df.Flaring, errors = 'coerce')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db902c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To convert all the columns we want, we can use apply:\n",
    "##########\n",
    "convert_cols = ['Total', 'Solid', 'Liquid', 'Gas', 'Cement', 'Flaring', 'Per_Capita', 'Bunker']\n",
    "\n",
    "df[convert_cols] = df[convert_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43576c33",
   "metadata": {},
   "source": [
    "#### Read only specific columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b39235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: If all we wanted was Nation, Year, Total, and Per_Capita:\n",
    "#Add usecols: Note we can use the new names\n",
    "\n",
    "df = pd.read_csv(local_file, skiprows = 5, header = None, names = name_list,\n",
    "                 usecols = ['Nation', 'Year', 'Total', 'Per_Capita'], na_values = '. ')\n",
    "\n",
    "#Could also use column integer index:\n",
    "#df = pd.read_csv(local_file, skiprows = 5, header = None, names = name_list,\n",
    "#                 usecols = [0, 1, 2, 8], na_values = '. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8296bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2fdf87",
   "metadata": {},
   "source": [
    "#### Filter the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc0449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once again, reload:\n",
    "#Let's just define a function at this point...\n",
    "\n",
    "def get_carbon_df():\n",
    "    local_file = r'Data/nation.1751_2017.csv'\n",
    "    \n",
    "    name_list = ['Nation', 'Year', 'Total', 'Solid', 'Liquid', 'Gas', 'Cement', 'Flaring', 'Per_Capita', 'Bunker']\n",
    "    new_df = pd.read_csv(local_file, header = 4, names = name_list, na_values = '. ')\n",
    "    \n",
    "    #Throw in stripping the whitespace from the names too:\n",
    "    new_df.Nation = new_df.Nation.str.strip()\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e40596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once again, reload:\n",
    "df = get_carbon_df()\n",
    "\n",
    "#We managed to get NaNs where the data was missing, can we filter out more?\n",
    "#Yes, but first:\n",
    "\n",
    "#This snippet gets the rows where anything is null:\n",
    "display(df[df.isnull().any(axis=1)]);\n",
    "\n",
    "#How many entries have a NaN?\n",
    "len(df[df.isnull().any(axis=1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fb418c",
   "metadata": {},
   "source": [
    "Our main NA handling methods:\n",
    "\n",
    "- `dropna()`\n",
    "- `fillna()`\n",
    "- `isnull()`\n",
    "- `notnull()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a9ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can either drop any rows with NAs:\n",
    "df2 = df.dropna()\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3595c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or fill them with something, like 0, if that seems appropriate:\n",
    "df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13896825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also fill different columns with different values:\n",
    "#Use a dictionary...\n",
    "\n",
    "#First, get a dataframe with lots of NaNs to better demo:\n",
    "df_bad = df[df.isnull().any(axis=1)]\n",
    "\n",
    "#Sample 20 of the finest rows!\n",
    "df_bad.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78efccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that we can get false positive SettingWithCopyWarnings\n",
    "df_bad.loc[:,'Flaring'] = 99\n",
    "df_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afff16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now fill NaNs in only very select columns using a dictionary\n",
    "\n",
    "df_bad.fillna({'Per_Capita': 999999, 'Flaring':-888}).sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfead2e",
   "metadata": {},
   "source": [
    "#### Back to dropping..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e627f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also restrict ourself to only dropping rows that are *all* NaN:\n",
    "########\n",
    "\n",
    "df2 = df.dropna(how = 'all')\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08cc001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or if specific columns have NaNs:\n",
    "########\n",
    "\n",
    "df2 = df.dropna(subset = ['Solid', 'Flaring'])\n",
    "\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d132844e",
   "metadata": {},
   "source": [
    "#### Drop columns with NaNs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7872f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set our axis to 1 and we will drop columns that contain any NaNs:\n",
    "df2 = df.dropna(axis = 1) #, how = 'all') #, subset=[0]\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e1ddc5",
   "metadata": {},
   "source": [
    "### Using GroupBy with Pandas\n",
    "\n",
    "1. *Split* DataFrame into groups based on one or more *keys*, along a particular axis (rows, `axis = 0`; or colums, `axis = 1`)\n",
    "2. Apply a function to each group, producing a new value\n",
    "3. Comine results into a new object\n",
    "\n",
    "<img src=\"split_apply_flow.jpg\" alt=\"drawing\" style=\"width:550px;\"/>\n",
    "\n",
    "Let's demo with something simpler, and then return to our carbon emissions dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c718598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a simple dataframe\n",
    "df = pd.DataFrame({'key1': ['a', 'a', 'b', 'b', 'a'],\n",
    "                   'key2': ['one', 'two', 'one', 'two', 'one'],\n",
    "                   'data1': [20, 30, 40, 50, 60],\n",
    "                   'data2': [10, 11, 12, 13, 14]})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb2fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's say we want the mean of our data grouped by key1:\n",
    "df_grouped = df.groupby('key1')\n",
    "\n",
    "#Now we have a GroupBy object:\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count how many are in each group:\n",
    "df_grouped.size()\n",
    "\n",
    "#Or:\n",
    "#df_grouped.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f317016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Do the means:\n",
    "##############\n",
    "\n",
    "df_grouped.mean()\n",
    "\n",
    "#type(df_grouped.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82824937",
   "metadata": {},
   "source": [
    "Note that the `key2` column was dropped above, as it is non-numeric and a mean would not make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#key1 is now our index. To reset to a column:\n",
    "#############\n",
    "\n",
    "df_grouped.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb3d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that the above is a DataFrameGroupBy object\n",
    "#Can also get a SeriesGroupBy object:\n",
    "\n",
    "grouped = df['data1'].groupby(df['key1'])\n",
    "\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514fcf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And get mean: (Or sum, etc.)\n",
    "grouped.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c71db8",
   "metadata": {},
   "source": [
    "We can group by multiple keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ee537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby(by = ['key1', 'key2'])\n",
    "\n",
    "#We get mean by two keys, and note the object that is created is a DataFrame\n",
    "df_means = df_grouped.mean()\n",
    "df_means\n",
    "\n",
    "#type(df_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf7076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The above Dataframe has a hierarchical index, consisting of unique pairs of the keys:\n",
    "df_means.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d2af40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#And we can turn this hierarchical index into columns by reseting the index:\n",
    "df_means.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeffd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also get the sizes of our various groups:\n",
    "df.groupby(by = ['key1', 'key2']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87332eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OR:\n",
    "df.groupby(by = ['key1', 'key2']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674dd42f",
   "metadata": {},
   "source": [
    "#### We can iterate over groupby objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4505201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For example:\n",
    "for name, group in df.groupby(by = 'key1'):\n",
    "    print(name, '\\n')\n",
    "    print(group, '\\n')\n",
    "    \n",
    "    #group now is a DataFrame we could use however we like\n",
    "    print(type(group))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5548204b",
   "metadata": {},
   "source": [
    "Lots more cool grouping that can be done, consult the docs for more!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e56882",
   "metadata": {},
   "source": [
    "#### Can also apply your own aggregation functions to groupby objects: Use `agg()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21045171",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_to_trough = lambda x: x.max() - x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8922cb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Again, simple grouping:\n",
    "df_grouped = df.groupby('key1')\n",
    "\n",
    "df_grouped.agg(peak_to_trough)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a58015",
   "metadata": {},
   "source": [
    "### Back to emissions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48a5ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab the data again, and remind ourselves\n",
    "df = get_carbon_df()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55682e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can group by nation, get sum of emissions\n",
    "df_grouped = df.groupby(by = 'Nation')\n",
    "\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a DataFrame of just the sums:\n",
    "df_sums = df_grouped.sum()\n",
    "\n",
    "#Note that Year and Per_Capita are now meaningless\n",
    "\n",
    "#If we just wanted Total:\n",
    "#df_sums = df_grouped[['Total']].sum()\n",
    "\n",
    "display(df_sums.head())\n",
    "\n",
    "#Plot the Total cumulative emissions histogram:\n",
    "df_sums['Total'].hist(bins = 50, edgecolor='black', facecolor=(.5, .1, .1), grid=False, log=True, figsize=(8,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0b4a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How much fossil (+cement) carbon has been emmitted by all countries since 1750??\n",
    "#In Million Metric Tons\n",
    "#Note that the following is a Series object:\n",
    "df_sums.sum() / 1e6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271ba8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the top cumulative emitters:\n",
    "#Divide by 1e6 to convert to million metric tons\n",
    "######\n",
    "\n",
    "df_sums.sort_values(by = ['Total'], ascending=False).head(20) / 1e6\n",
    "\n",
    "#Get number one:\n",
    "#df_sums.sort_values(by = ['Total'], ascending=False).head(20).index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73258d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can also plot all the variables:\n",
    "###\n",
    "#Let's add a bigger figure/axis:\n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(12,8))\n",
    "\n",
    "#Exclude Year:\n",
    "df_sums.iloc[:,1:9].hist(bins = 30, ax = ax1, edgecolor='black', facecolor=(.5, .1, .1), grid=False, log=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eba4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To put Nation name, which is now the index, back to a column:\n",
    "#####\n",
    "\n",
    "df_sums.reset_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec37b968",
   "metadata": {},
   "source": [
    "### Now let's get cumulative emissions and plot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4549ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_carbon_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bedf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following bit of code with groupby Nation will take cumulative sum down the years:\n",
    "#Could do this:\n",
    "#df = df.fillna(0)\n",
    "\n",
    "df_cumulative = df.copy()\n",
    "\n",
    "#df_cumulative Per_Capita: Doesn't make sense to cumulative sum\n",
    "df_cum.drop(columns = 'Per_Capita', inplace=True)\n",
    "\n",
    "\n",
    "convert_cols = ['Total', 'Solid', 'Liquid', 'Gas', 'Cement', 'Flaring', 'Bunker']\n",
    "\n",
    "#Note we preserve the Year, doing this\n",
    "#NOte the division by 1e6\n",
    "df_cumulative[convert_cols] = df.groupby(by = ['Nation'])[convert_cols].cumsum() / 1e6\n",
    "\n",
    "display(df_cumulative.head())\n",
    "\n",
    "#Plot the results for the US:\n",
    "df_cumulative.loc[df_cumulative['Nation'] == 'UNITED STATES OF AMERICA'].plot(x = 'Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117ca364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following is an alternative method to take the cumulative sums (preserving year):\n",
    "######\n",
    "\n",
    "#df_cumulative = df.copy()\n",
    "\n",
    "#Drop Per_Capita: Doesn't make sense to cumulative sum\n",
    "df_cumulative.drop(columns = 'Per_Capita', inplace=True)\n",
    "\n",
    "df_cumulative = df.groupby(by = ['Nation', 'Year'])\n",
    "df_cumulative = df_cumulative.sum().groupby(level=0).cumsum().reset_index()\n",
    "\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa1b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We could use grouping to plot individual country time-series:\n",
    "####\n",
    "\n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(14,8))\n",
    "\n",
    "#Sneak in an enumerate:\n",
    "####\n",
    "for i, (name, group) in enumerate(df_cumulative.groupby(by = 'Nation')):\n",
    "    #print(name, '\\n')\n",
    "    #print(group, '\\n')\n",
    "    \n",
    "    group.plot(x = 'Year', y = 'Total', ax = ax1, legend=False, logy=True, label=name)\n",
    "    \n",
    "    if (i > 25):\n",
    "        break\n",
    "        \n",
    "ax1.legend(ncol=2, loc='upper left', fontsize=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d2a65c",
   "metadata": {},
   "source": [
    "#### Get Total Cumulative Emissions by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0150f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's group by year and sum, to get total global emissions!:\n",
    "########\n",
    "\n",
    "df_world = df_cumulative.groupby(by = 'Year').sum()\n",
    "\n",
    "df_world = df_world.reset_index()\n",
    "\n",
    "#We have some very odd points where the cumulative sums go down:\n",
    "df_world.plot(x = 'Year', figsize=(8,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a60dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's compare the above to the provided global emissions data series...\n",
    "####\n",
    "\n",
    "url_name = 'https://zenodo.org/record/4281271/files/global.1751_2017.csv?download=1'\n",
    "\n",
    "#Let's go ahead and download...\n",
    "global_file = r'Data/global.1751_2017.csv'\n",
    "\n",
    "#Download and save\n",
    "request.urlretrieve(url_name, global_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f988c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No Nation or Bunker columns for this dataset:\n",
    "name_list = ['Year', 'Total', 'Solid', 'Liquid', 'Gas', 'Cement', 'Flaring', 'Per_Capita']\n",
    "\n",
    "df_global = pd.read_csv(global_file, header = 4, names = name_list)\n",
    "df_global.head()\n",
    "\n",
    "#This is the global yearly emissions series:\n",
    "df_global.plot(x = 'Year', figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef407a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What do we have as our grand totals?\n",
    "df_global.sum() / 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab126f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare to our previous:\n",
    "df_sums.sum() / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e4896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take the cumulative sums and look at our time-series...\n",
    "#####\n",
    "df_global_cum = df_global.copy()\n",
    "\n",
    "df_global_cum.iloc[:,1:8] = df_global.iloc[:,1:8].cumsum()\n",
    "\n",
    "\n",
    "\n",
    "#Plot the new data and the old, just the Totals\n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(8,6))\n",
    "\n",
    "df_global_cum[['Total', 'Year']].plot(x = 'Year', ax = ax1)\n",
    "\n",
    "#Need to divide by 1000: Different unit scalings for the datasets\n",
    "ax1.plot(df_world.Year, df_world.Total / 1000, label='Summed Total')\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee00551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And look at our dataframe\n",
    "df_global_cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd78c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn out, there are negative values in the National series, e.g.:\n",
    "####\n",
    "\n",
    "df.loc[df['Nation'] == 'ISLAMIC REPUBLIC OF IRAN'].plot(x = 'Year')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0fd585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see all the values < 0:\n",
    "df.loc[df['Total'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9650c7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's filter any negative values in the national series to 0\n",
    "#Unclear why this happened, but oh well let's try...\n",
    "\n",
    "df = get_carbon_df()\n",
    "\n",
    "#Iterate through everything but Names and Year:\n",
    "#Also track total negative values for the Total column\n",
    "neg_sum = 0\n",
    "\n",
    "for k in df.columns[2:]:\n",
    "    if (k == 'Total'):\n",
    "        neg_sum = neg_sum + df.loc[df[k] < 0, k].sum()\n",
    "    \n",
    "    df.loc[df[k] < 0, k] = 0\n",
    "    \n",
    "neg_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9625bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm filtering!\n",
    "\n",
    "df.loc[df['Total'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6555b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now plot again:\n",
    "\n",
    "df.loc[df['Nation'] == 'ISLAMIC REPUBLIC OF IRAN'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411444be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's repeat the steps above...\n",
    "\n",
    "#We have our shiny new, filtered df:\n",
    "df_cumulative = df.copy()\n",
    "\n",
    "\n",
    "#Drop Per_Capita: Doesn't make sense to cumulative sum\n",
    "df_cumulative.drop(columns = 'Per_Capita', inplace=True)\n",
    "\n",
    "convert_cols = ['Total', 'Solid', 'Liquid', 'Gas', 'Cement', 'Flaring', 'Bunker']\n",
    "\n",
    "df_cumulative[convert_cols] = df.groupby(by = ['Nation'])[convert_cols].cumsum()\n",
    "\n",
    "#Let's group by year and sum, to get total global emissions!:\n",
    "########\n",
    "\n",
    "df_world = df_cumulative.groupby(by = 'Year').sum()\n",
    "\n",
    "\n",
    "#We *still* have some very odd points where the cumulative sums go down:\n",
    "df_world.plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb3d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First shifts happen around 1947\n",
    "display(df_world.loc[1947] - df_world.loc[1946])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7078824e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's see how many countries are contributing at each year:\n",
    "\n",
    "num_countries = df_cum.groupby('Year').size()\n",
    "\n",
    "num_countries.plot()\n",
    "\n",
    "#How many countries around from 1940 through 1960?\n",
    "display(num_countries[(num_countries.index < 1960) & (num_countries.index > 1940)])\n",
    "\n",
    "#How many countries around from 1975 through 1995?\n",
    "display(num_countries[(num_countries.index > 1975) & (num_countries.index < 1995)])\n",
    "\n",
    "#Turns out different counties have data for some years, so get the jumps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The one that explains dip at 1947: Germany!\n",
    "####\n",
    "\n",
    "for k, (name, group) in enumerate(df_cum.groupby(by = 'Nation')):\n",
    "    \n",
    "    if 1946 in group.Year.values and not (1947 in group.Year.values):\n",
    "        print(name)\n",
    "\n",
    "    #What about:\n",
    "    #And flip these also:\n",
    "    #if 1992 in group.Year.values and not (1989 in group.Year.values):\n",
    "    #    print(name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a6581",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cum.loc[df_cum['Nation'] == 'GERMANY'].plot(x = 'Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d94d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And what where Germany's emissions 1946:\n",
    "df_cumulative.loc[df_cumulative['Nation'] == 'GERMANY'].loc[df_cumulative['Year'] == 1946]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e84db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And difference 1946 to 1947 calculated global cumulative?\n",
    "df_world.loc[1947] - df_world.loc[1946]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bdf26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dip in the early 1990s?\n",
    "#Clearly related to the breakup of the former Soviet Union and the reshuffling of countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a4612",
   "metadata": {},
   "source": [
    "### Plotting With Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2b13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We've already plotted some times-series\n",
    "#Let's just use our global times-series here\n",
    "\n",
    "#We can specify an axis as above:\n",
    "fig1, ax1 = plt.subplots(1,1, figsize=(8,6))\n",
    "\n",
    "\n",
    "#Recall plotting one series in the dataframe:\n",
    "df_global.plot(x = 'Year', y = 'Total', ax=ax1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839b43d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And plotting several:\n",
    "fig1, ax1 = plt.subplots(1,1, figsize=(8,6))\n",
    "\n",
    "#df_global.plot(x = 'Year', y = ['Solid', 'Liquid', 'Gas'], ax=ax1)\n",
    "\n",
    "#For all:\n",
    "df_global.plot(x = 'Year', ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db5f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can also do cumulative sum like so\n",
    "fig1, ax1 = plt.subplots(1,1, figsize=(8,6))\n",
    "\n",
    "df_global.cumsum().plot(x = 'Year', y = ['Solid', 'Liquid', 'Gas'], ax=ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54581f0",
   "metadata": {},
   "source": [
    "Can specify `kind` argument to `plot()` method, with options:\n",
    "\n",
    "- `bar` or `barh` for bar plots\n",
    "\n",
    "- `hist` for histogram\n",
    "\n",
    "- `box` for boxplot\n",
    "\n",
    "- `kde` or `density` for density plots\n",
    "\n",
    "- `area` for area plots\n",
    "\n",
    "- `scatter` for scatter plots\n",
    "\n",
    "- `hexbin` for hexagonal bin plots\n",
    "\n",
    "- `pie` for pie plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd35c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's do an area plot:\n",
    "#######\n",
    "\n",
    "fig1, ax1 = plt.subplots(1,1, figsize=(8,6))\n",
    "\n",
    "df_global.plot(x = 'Year', kind = 'area', ax = ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b404ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#But we don't really want Total or Per_Capita\n",
    "#Let's exclude:\n",
    "df2 = df_global.loc[:, df_global.columns.difference(['Total', 'Per_Capita'])]\n",
    "\n",
    "\n",
    "fig1, ax1 = plt.subplots(1,1, figsize=(8,6), dpi=90)\n",
    "\n",
    "#Plot: Can change the colormap to various options:\n",
    "df2.plot(x = 'Year', kind = 'area', ax = ax1, cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f7ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da19f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And cumsum:\n",
    "fig1, ax1 = plt.subplots(1,1, figsize=(8,6), dpi=90)\n",
    "\n",
    "#Let's preserve year here:\n",
    "df2.iloc[:,:-1] = df2.iloc[:,:-1].cumsum()\n",
    "\n",
    "#And plot:\n",
    "df2.plot(x = 'Year', kind = 'area', ax = ax1, cmap='Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a24b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note pd.to_datetime:\n",
    "#Also note that we need to convert to a string first:\n",
    "df2.Year = pd.to_datetime(df2.Year.astype(str))\n",
    "\n",
    "#And plot:\n",
    "fig1, ax1 = plt.subplots(1,1,figsize=(8,6), dpi=90)\n",
    "df2.plot(x = 'Year', kind = 'area', ax = ax1, cmap='Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03e4d75",
   "metadata": {},
   "source": [
    "### Finally, melt + a pie chart..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd4eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.iloc[-1:-2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b096e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's get a DataFrame that is just our last year\n",
    "final_emissions = df2.iloc[-1:-2:-1]\n",
    "\n",
    "final_emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c85c417",
   "metadata": {},
   "source": [
    "We'd like to make a pie chart showing the relative contributions of each fossil type, but pie() takes a single column as the `y` argument\n",
    "\n",
    "Let's `melt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1447ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = pd.melt(final_emissions, id_vars=['Year'], value_vars=final_emissions.columns[0:5],\n",
    "        var_name='Category', value_name='Emissions')\n",
    "\n",
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0966a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot make our much anticipated pie chart:\n",
    "df_long.plot.pie(y = 'Emissions', figsize=(6,6))\n",
    "\n",
    "#Gah! Labels are all wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6727961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To fix, let's set our index:\n",
    "df_long = df_long.set_index('Category')\n",
    "\n",
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07620f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot our even more anticipated pie chart:\n",
    "fig1, ax1 = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "df_long.plot.pie(y = 'Emissions', figsize=(6,6), fontsize=14, ax=ax1)\n",
    "\n",
    "#Try with and without this:\n",
    "ax1.legend(fontsize=14, loc='upper right', bbox_to_anchor=(1.4, 1))\n",
    "ax1.set_ylabel('Emissions', fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b5029d",
   "metadata": {},
   "source": [
    "### Some simpler plotting demos from here out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de770e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Just make some random stuff:\n",
    "df = pd.DataFrame(np.random.rand(10, 4).round(2)*100, columns=list(\"ABCD\"))\n",
    "\n",
    "#Note that we can mix in other matplotlib plotting on the same axis:\n",
    "####\n",
    "\n",
    "fig1, ax1 = plt.subplots(1,1, figsize=(8,6))\n",
    "df.plot(ax = ax1, linewidth=3, cmap='Reds')\n",
    "\n",
    "#Add some matplotlib\n",
    "x = np.arange(0,10)\n",
    "y = x*10\n",
    "ax1.plot(x, y, linewidth=5, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faffa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bec3520",
   "metadata": {},
   "source": [
    "#### Can also plot using method pd.plot.\\<kind\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3efe40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can try:\n",
    "#df.plot.<TAB>\n",
    "df.plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a09c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do a simple bar plot:\n",
    "df.iloc[1].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94edbf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do a slightly less simple:\n",
    "df.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ec40a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To stack, or do horizontal:\n",
    "fig1, ax1 = plt.subplots(1,2, figsize=(14,6))\n",
    "\n",
    "df.plot.bar(ax = ax1[0], stacked=True)\n",
    "df.plot.barh(ax = ax1[1], stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19713401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can make a boxplot:\n",
    "df.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5799d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or:\n",
    "#We can also plot one column or more column, grouped by another:\n",
    "\n",
    "#Remake df with more points:\n",
    "df = pd.DataFrame(np.random.rand(10, 4), columns=list(\"ABCD\"))\n",
    "\n",
    "#Set column C = [1, 1, 1, 1, 1, 2, 2, 2, 2, 2], but more compactly:\n",
    "df[\"C\"] = np.array([1]*5 + [2]*5)\n",
    "\n",
    "fig1, ax1 = plt.subplots(1,1, figsize=(14,6))\n",
    "\n",
    "df.boxplot(column = [\"A\"], by = \"C\", ax = ax1) #, grid=False)\n",
    "\n",
    "#ax1.grid(False)\n",
    "#fig1.suptitle('Replace the Default');\n",
    "#ax1.set_title('Replace this default too')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1748177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can do custom colors, positions, and widths, etc:\n",
    "####\n",
    "\n",
    "my_colors = {\n",
    "    \"boxes\": \"DarkGreen\",\n",
    "    \"whiskers\": \"DarkOrange\",\n",
    "    \"medians\": \"DarkBlue\",\n",
    "    \"caps\": \"Gray\",\n",
    "}\n",
    "\n",
    "my_positions = [1, 4, 5, 7]\n",
    "my_widths = [.5, 1.5, .75, .2]\n",
    "\n",
    "df.plot.box(color = my_colors, sym='*', vert=False,\n",
    "             positions=my_positions,\n",
    "             widths=my_widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5defda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And can do custom box, whisker, cap, flier, and median props:\n",
    "boxprops = dict(linewidth = 3, color = 'black')\n",
    "\n",
    "whiskerprops = dict(linestyle = '-', linewidth=3, color='red')\n",
    "boxprops = dict(linewidth = 3, color = 'red')\n",
    "capprops = dict(linewidth = 3, color = 'red')\n",
    "flierprops = dict(markersize=10, markeredgewidth=2, markeredgecolor='red', markerfacecolor='red')\n",
    "medianprops = dict(linewidth = 3, color = 'red')\n",
    "\n",
    "df.boxplot(boxprops = boxprops,\n",
    "            whiskerprops = whiskerprops,\n",
    "            capprops = capprops,\n",
    "            flierprops = flierprops,\n",
    "            medianprops = medianprops,\n",
    "            rot = 45, grid=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c8e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a pie plot from a Series: y value unambiguous here (vs DataFrame)\n",
    "###\n",
    "\n",
    "df.iloc[2].plot.pie();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67743f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histograms, again:\n",
    "####\n",
    "\n",
    "df3 = pd.DataFrame({\"A\":np.random.randn(1000) - 1, \"B\":np.random.randn(1000), \"C\":np.random.randn(1000) + 1})\n",
    "\n",
    "\n",
    "fig1, ax1 = plt.subplots(1,2, figsize=(14,6))\n",
    "\n",
    "df3.plot.hist(alpha=0.5, bins=30, ax=ax1[0])\n",
    "df3.plot.hist(stacked=True, bins=30, ax=ax1[1]) #orientation=\"horizontal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2d5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can plot on multiple subplots like so:\n",
    "fig1, ax1 = plt.subplots(1,1, figsize=(12,6))\n",
    "\n",
    "df3.hist(color=\"darkblue\", bins=50, ax=ax1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63efe664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also can do a kernel density estimate:\n",
    "#####\n",
    "fig1, ax1 = plt.subplots(1,1, figsize=(12,6))\n",
    "\n",
    "df3['A'].plot.kde(bw_method=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8227c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot both histogram and kde together...\n",
    "fig1, ax1 = plt.subplots(1,1, figsize=(12,6))\n",
    "\n",
    "df3['A'].hist(color=\"darkblue\", bins=50, ax=ax1, alpha=.5, density=True)\n",
    "\n",
    "x = df3['A'].plot.kde(ax=ax1, linewidth=5, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dd22dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Want to integrate the kernel?\n",
    "#############\n",
    "\n",
    "import scipy\n",
    "\n",
    "#Estimate the kernel\n",
    "kernel = scipy.stats.gaussian_kde(df3['A'])\n",
    "\n",
    "#Get the kernel at certain points:\n",
    "y = kernel(np.linspace(-8,8,100))\n",
    "\n",
    "display(type(y))\n",
    "\n",
    "plt.plot(y.cumsum() / y.sum())\n",
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad8d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All together:\n",
    "\n",
    "fig1, ax1 = plt.subplots(1,1, figsize=(12,6))\n",
    "\n",
    "h = df3['A'].hist(color=\"darkblue\", bins=50, ax=ax1, alpha=.5, density=True)\n",
    "\n",
    "x = df3['A'].plot.kde(ax=ax1, linewidth=5, color='red')\n",
    "\n",
    "#Estimate the kernel\n",
    "kernel = scipy.stats.gaussian_kde(df3['A'])\n",
    "\n",
    "#Get the kernel at certain points:\n",
    "x_points = np.linspace(-8,8,100)\n",
    "y = kernel(x_points)\n",
    "\n",
    "ax1.plot(x_points, y.cumsum() / y.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07eeab9",
   "metadata": {},
   "source": [
    "Finally, the hexbin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e44c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Make a hexbin!\n",
    "\n",
    "df3.plot.hexbin(x = 'A', y='B', gridsize=20, cmap='viridis', figsize=(8,8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c176ae",
   "metadata": {},
   "source": [
    "As always, there's a lot more you can do with Pandas, grouping, plotting, and so on..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
